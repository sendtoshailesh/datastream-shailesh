      ./cloud_sql_proxy -instances=shailesh-1:asia-south1:pg-db11=tcp:0.0.0.0:5431


CREATE PUBLICATION MY_PUBLICATION FOR ALL TABLES;
SELECT PG_CREATE_LOGICAL_REPLICATION_SLOT('XBY','PGOUTPUT');

dvdrental=> select * from pg_replication_slots;
 slot_name |  plugin  | slot_type | datoid | database  | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn
-----------+----------+-----------+--------+-----------+-----------+--------+------------+------+--------------+-------------+---------------------
 debezium  | wal2json | logical   |  16691 | dvdrental | f         | f      |            |      |       258729 | 1/458EBDD0  | 1/45A7A578
(1 row)

dvdrental=> select * from pg_publication;
 pubname | pubowner | puballtables | pubinsert | pubupdate | pubdelete
---------+----------+--------------+-----------+-----------+-----------
(0 rows)

dvdrental=> CREATE PUBLICATION MY_PUBLICATION FOR ALL TABLES;
CREATE PUBLICATION
dvdrental=> select * from pg_publication;
    pubname     | pubowner | puballtables | pubinsert | pubupdate | pubdelete
----------------+----------+--------------+-----------+-----------+-----------
 my_publication |    16388 | t            | t         | t         | t
(1 row)

dvdrental=> select * from pg_publication;
    pubname     | pubowner | puballtables | pubinsert | pubupdate | pubdelete
----------------+----------+--------------+-----------+-----------+-----------
 my_publication |    16388 | t            | t         | t         | t
(1 row)

dvdrental=>

dvdrental=> select pg_create_logical_replication_slot('abc','pgoutput');
 pg_create_logical_replication_slot
------------------------------------
 (abc,1/47BD22D0)
(1 row)

dvdrental=>

select * from accounts limit 10;

update accounts set password='chang1' where user_id=2;



export PROJECT_ID=shailesh-1

gcloud beta dataflow flex-template run datastream-replication \
        --project="${PROJECT_ID}" --region="us-central1" \
        --template-file-gcs-location="gs://dataflow-templates-us-central1/latest/flex/Cloud_Datastream_to_BigQuery" \
        --enable-streaming-engine \
        --parameters \
inputFilePattern="gs://shailesh-ds1/data/",\
gcsPubSubSubscription="projects/${PROJECT_ID}/subscriptions/datastream-subscription",\
outputProjectId="${PROJECT_ID}",\
outputStagingDatasetTemplate="dataset",\
outputDatasetTemplate="dataset",\
outputStagingTableNameTemplate="{_metadata_schema}_{_metadata_table}_log",\
outputTableNameTemplate="{_metadata_schema}_{_metadata_table}",\
deadLetterQueueDirectory="gs://dataflow-staging-us-central1-664290125703/dlq/",\
maxNumWorkers=2,\
autoscalingAlgorithm="THROUGHPUT_BASED",\
mergeFrequencyMinutes=2,\
inputFileFormat="avro"



export PROJECT_ID=shailesh-1

gcloud beta dataflow flex-template run datastream-replication \
        --project="${PROJECT_ID}" --region="asia-south1" \
        --template-file-gcs-location="gs://dataflow-templates-asia-south1/latest/flex/Cloud_Datastream_to_BigQuery" \
        --enable-streaming-engine \
        --network="sh-vpc" \
        --subnetwork="https://www.googleapis.com/compute/v1/projects/shailesh-1/regions/asia-south1/subnetworks/subnet-mumbai" \
        --parameters \
inputFilePattern="gs://datastream-mumbai-shailesh/data20220915/",\
gcsPubSubSubscription="projects/${PROJECT_ID}/subscriptions/datastream-subscription",\
outputProjectId="${PROJECT_ID}",\
outputStagingDatasetTemplate="dataset",\
outputDatasetTemplate="dataset",\
outputStagingTableNameTemplate="{_metadata_schema}_{_metadata_table}_log",\
outputTableNameTemplate="{_metadata_schema}_{_metadata_table}",\
deadLetterQueueDirectory="gs://dataflow-staging-us-central1-664290125703/dlq/",\
maxNumWorkers=2,\
autoscalingAlgorithm="THROUGHPUT_BASED",\
mergeFrequencyMinutes=2,\
inputFileFormat="avro"



